{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 2.10.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from textwrap import wrap\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print('TensorFlow Version ' + tf.__version__)\n",
    "\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:16:19.036297100Z",
     "start_time": "2024-03-23T17:16:19.024768600Z"
    }
   },
   "id": "f471a244ce09db7d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_size = 384\n",
    "batch_size = 16\n",
    "n_classes = 3\n",
    "EPOCHS = 40\n",
    "\n",
    "train_path = 'dataset/train'\n",
    "valid_path = 'dataset/valid'\n",
    "test_path = 'dataset/test'\n",
    "\n",
    "classes = {0: \"Dry\",\n",
    "           1: \"Normal\",\n",
    "           2: \"Wet\"}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:16:19.587732400Z",
     "start_time": "2024-03-23T17:16:19.579071900Z"
    }
   },
   "id": "de69b5c97a329226",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def data_augment(image):\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float16)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float16)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float16)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float16)\n",
    "\n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "\n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3)  # rotate 270ยบ\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2)  # rotate 180ยบ\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1)  # rotate 90ยบ\n",
    "\n",
    "    # Pixel-level transforms\n",
    "    if p_pixel_1 >= .4:\n",
    "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:16:12.512412200Z",
     "start_time": "2024-03-23T17:16:12.505078100Z"
    }
   },
   "id": "1e4250063a61009e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 247 images belonging to 3 classes.\n",
      "Found 12 images belonging to 3 classes.\n",
      "Found 145 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                                                samplewise_center=True,\n",
    "                                                                samplewise_std_normalization=True,\n",
    "                                                                dtype='float16')\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                                               samplewise_center=True,\n",
    "                                                               samplewise_std_normalization=True,\n",
    "                                                               dtype='float16')\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                                                samplewise_center=True,\n",
    "                                                                samplewise_std_normalization=True,\n",
    "                                                                dtype='float16')\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# same directory as training data\n",
    "\n",
    "valid_gen = train_datagen.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    color_mode='rgb',\n",
    "    shuffle=False,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    color_mode='rgb',\n",
    "    shuffle=False,\n",
    "    class_mode='categorical',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:19:24.169950500Z",
     "start_time": "2024-03-23T17:19:24.110534100Z"
    }
   },
   "id": "105f949de9dd5a3c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "train_labels = []\n",
    "for i in range(len(train_gen)):\n",
    "    _, labels = train_gen[i]\n",
    "    train_labels.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:19:31.512415600Z",
     "start_time": "2024-03-23T17:19:29.198578300Z"
    }
   },
   "id": "a1d0e5a14194b58e",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Patches(L.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID',\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bfb434743b8894b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "patch_size = 7  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "x = train_gen.next()\n",
    "image = x[0][0]\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f'Image size: {image_size} X {image_size}')\n",
    "print(f'Patch size: {patch_size} X {patch_size}')\n",
    "print(f'Patches per image: {patches.shape[1]}')\n",
    "print(f'Elements per patch: {patches.shape[-1]}')\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype('uint8'))\n",
    "    plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef3279a34d8f23b0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from vit_keras import vit\n",
    "\n",
    "vit_model = vit.vit_b16(\n",
    "    image_size=image_size,\n",
    "    activation='softmax',\n",
    "    pretrained=True,\n",
    "    include_top=True,\n",
    "    pretrained_top=False,\n",
    "    classes=200)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f61f5575fabd7d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vit_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.keras.activations.gelu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation=tf.keras.activations.gelu),\n",
    "    tf.keras.layers.Dense(3, 'softmax')\n",
    "],\n",
    "    name='vision_transformer')\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "427c095fcec3ee33"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class_weights_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "853470e551c6c633"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "learning_rate = 1e-5\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n",
    "STEP_SIZE_VALID = valid_gen.n // valid_gen.batch_size\n",
    "\n",
    "early_stopping_callbacks = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1)\n",
    "filepath = \"checkpoints/no-smoted-saved-model-{epoch:02d}.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,\n",
    "                                                               save_best_only=False, save_weights_only=False,\n",
    "                                                               mode='auto', period=1)\n",
    "\n",
    "History = model.fit(x=train_gen,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=50,\n",
    "                    callbacks=[early_stopping_callbacks, model_checkpoint_callback],\n",
    "                    class_weight=class_weights_dict)\n",
    "\n",
    "model.save(\"models/model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4181c1fa45edbd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_history(item):\n",
    "    plt.plot(History.history[item], label=item)\n",
    "    plt.plot(History.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(\"loss\")\n",
    "plot_history(\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72da69214bb37a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "predicted_classes = np.argmax(model.predict(test_gen, steps=test_gen.n // test_gen.batch_size + 1), axis=1)\n",
    "true_classes = test_gen.classes\n",
    "class_labels = list(test_gen.class_indices.keys())\n",
    "confusionmatrix = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(confusionmatrix, cmap='Blues', annot=True, cbar=True, fmt='g', xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "\n",
    "print(classification_report(true_classes, predicted_classes))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81be93850ea685a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f5b5639d47101ac9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
