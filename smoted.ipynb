{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:43:22.419721700Z",
     "start_time": "2024-03-18T20:43:22.407145400Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from textwrap import wrap\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow_addons as tfa\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "batch_size = 16\n",
    "n_classes = 3\n",
    "EPOCHS = 30\n",
    "\n",
    "train_path = 'C:\\\\Users\\\\matus\\\\PycharmProjects\\\\VisionTransformer\\\\test_smote_images'\n",
    "\n",
    "classes = {0 : \"Dry\",\n",
    "           1 : \"Normal\",\n",
    "           2 : \"Wet\"}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:45:31.962520Z",
     "start_time": "2024-03-18T20:45:31.946870500Z"
    }
   },
   "id": "68dd78c5c81853ee",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def data_augment(image):\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k = 3) # rotate 270ยบ\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k = 2) # rotate 180ยบ\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k = 1) # rotate 90ยบ\n",
    "        \n",
    "    # Pixel-level transforms\n",
    "    if p_pixel_1 >= .4:\n",
    "        image = tf.image.random_saturation(image, lower = .7, upper = 1.3)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta = .1)\n",
    "        \n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:45:32.464011Z",
     "start_time": "2024-03-18T20:45:32.456022700Z"
    }
   },
   "id": "a0a1ab26b537a7b8",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5973 images belonging to 3 classes.\n",
      "Found 1491 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                                          samplewise_center = True,\n",
    "                                                          samplewise_std_normalization = True,\n",
    "                                                          validation_split = 0.2,\n",
    "                                                          preprocessing_function = data_augment)\n",
    "# set as training data\n",
    "\n",
    "train_gen  = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size = batch_size,\n",
    "    seed = 1,\n",
    "    color_mode = 'rgb',\n",
    "    shuffle = True,\n",
    "    class_mode='categorical',\n",
    "    subset='training') \n",
    "\n",
    "# same directory as training data\n",
    "\n",
    "valid_gen  = datagen.flow_from_directory(\n",
    "    train_path ,\n",
    "    target_size=(224, 224),\n",
    "    batch_size = batch_size,\n",
    "    seed = 1,\n",
    "    color_mode = 'rgb',\n",
    "    shuffle = False,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "class_indices_mapping = train_gen.class_indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:45:33.752539800Z",
     "start_time": "2024-03-18T20:45:33.298501Z"
    }
   },
   "id": "45de327b5135a9be",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Patches(L.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = images,\n",
    "            sizes = [1, self.patch_size, self.patch_size, 1],\n",
    "            strides = [1, self.patch_size, self.patch_size, 1],\n",
    "            rates = [1, 1, 1, 1],\n",
    "            padding = 'VALID',\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:45:34.452972Z",
     "start_time": "2024-03-18T20:45:34.446367200Z"
    }
   },
   "id": "8b6ca61865f50677",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 224 X 224\n",
      "Patch size: 7 X 7\n",
      "Patches per image: 1024\n",
      "Elements per patch: 147\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 400x400 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFICAYAAAAyFGczAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAALxklEQVR4nO3d23bbOBIFUGpW//8vax6ylMg0i1eALAB7P0z3tO3EksijU+BFr/f7/Z4A+OV/T/8CAFkJSICAgAQICEiAgIAECAhIgICABAgISICAgAQI/Lf3G1+vV83fA+A2ey8g1CABAgISICAgAQICEiAgIAECAhIgICABAgISICAgAQICEiAgIAECAhIgICABAgISICAgAQK77wcJr2ma3rP/X9K+O/TBfQQkq+YhWPO2yRlvySy0x2bEhhUZQ5v7aJD8IhR++jwf2uR4NEh+EI6x1+T5GY0GyTRNdvwjNMpxaJAAAQ1ycJrjed/PnTbZJw1yUNbTyvJc9klADsjOXIc3nf4ISICANchBaDb3mV+SSbs0yAEIx/sZt/sgIAECArJjWszzPP9tE5CdGmXHHOVx8gwB2aHeQ2N+gnb2x/uatPlWCUiAgNN8OjJyQ2nlsj+nALVFQHZitHBce7zzr2ULJCHZDgHZuF6DcS1Ejq47ZgxMt0xrgzVIgIAG2bCe2uPRlvf5+pnnYOlnnmpyxu3cBGSjWg/Htd9/LTDmgVLqNB8jL0uM2DSj9TcF2qNBNqblkDjbGuc/u9Qi9/49W/b8bOmW2copSiMSkNziyrrf0cCL/txSby7WDcdhxG5Iy+3xTKCsXZ7X66V7PT6mlglIgIARO7leG8VSozzyWGuN53vVHLMdUc9DQFJFFEx37/Tff19rbzbWOp8nIBNrbYf+dnTHvnKEe+3nBQxXWIMECGiQPO5q+ztyZ5+aaqwdGrOfJSATanm0PqLECdJZnqu1E9lL/dmC8n5GbICABplMlkZUW+3LAe+wZ7TX+tomIKniakBkCcFMrEfeT0Am0moolLzdGOs003tZgwQIaJAJjNSeRnqs0xSPxZpgGwQkt7p6DXaLrqwdWnd8loB8WAs3U7jyqYAZP1Ewk63Xae3elp7L+qxBAgQ0yAf1PlpO0/YHcLF9qWW0XqlF1icg2TTfUXs4ybsFDuQ8z4j9EEEB+QnIB2QOx14/6+Vp8+f1PV1rht9t3utVjxG7Q2d2mPnP1Nrp5uM65xi776FB3uyOYDjaToTVc/beLX3pNZrfYo3yBCRAwIjNbbSc61fVcC8N8iYW0/moefUUZWmQVGWn3faezj9PzpWsS4OEBARcThokPKBU81u6/LDEn8sfAvIGWcbMEp8iCCMxYkMCWd5E+UmDHNRdJ6zf+fe16Orz4k4/dWmQlQkGaJcGSVFayzOWGqMDNtdpkAABDbISo7Xn4E5aYh0CkqKEIj0xYlcgJLjb2rX+tsfzBCRAQEDCALTIcwRkYTZE6IeAhI54gy5LQEJn3Jy5HAHZITsIzossw3mQhWQKpGjncPOIsbmBxXEaJAzEG+MxGiR0aCkItcfjNEiAgIAckDEL9hGQMBhvkPsJyAJscLTA6V/HCUiAgIAECDjNZyB7xysnlMMfGuQF1nRole12HwE5kPf0+2Thpf8G/CEgAQLWIPnF+AV/CMiTWg4RIzXT9G8btj3EjNgwmJbf3O8mIAECRmwY0HeLNGLHNMgTjCgwBgEJEBCQMDgTUUxAYgeBgIM0MCgHZ7ZpkIApIiAgAQJG7AN6fJft8TGxz/elhsbtZQJyQEKROddlLzNiAwQ0SFLwMQ9kpEEOxEdEsMQ2EROQAAEj9kA+Y2zGxpDxdwINckCOVMI+AnInDQfGIyABAgJyQNowEdvGTwISIOAo9kAytYPMR9R75WT84zRIHuWIOpkJSICAgIQBae77CEiAgIDkcdoMWQnIHRzxKye6e7WQJCMBSRpu/U82AhIg4ETxAVgiYJp+bgdrbf218rXRCEhI6vXrX/55//0fajJiQ1LvaQrr/2uaptfLx2jUJiABAgKSW601Hm3ot71TtOetDmuQPMIOXcjniby4Hlnoj+mOBgkQ0CAhm9fivxb/K7TFbRokJGUZ4nkaJCQjGPPQIAECGiRkcrY+nlhU1FS3CcgVNiCa4YhLFQISGva+EIwydZs1SICAgAQIGLEhk/e/0fdlEfxxGiQMap6/8vg3DRKSek/1Q0sortMgIau3I81P0yAHsLWTaRGNKniKj21gmQYJEBCQkFnUEs3etzBiQ3Kfq2VqjsHydpkGCY0QYvcTkAABIzY0SJu8h4DEKR8NEYz3MmID0zR5Y1wiIGFArsPex4g9EDsB32wP2wTkQP7eRiv470tfg5EZsQECAhL4ywTxk4Bc8Z6cVgEjswY5kKgdaA2wTIMECAjIQWiJcJyABAgISICAgByA8Zq9nLXxk4AECAjIAWgFfNs6v9f28o+ABAgISICAgByEsQmOc6lhIz5HoqOge6187cNtzZgmr/0RGiRAQINs2Npt843UcJ0GucOTYfOajETwFAEJEDBiD8oBG769Z//kDwGZyJ6g2htma99nJ4B9BGQi8+Dy6YPwLGuQAAENckDaJ98sucQ0yAH4dEY4R0AmotlBLgISICAgd3piRDUWw7McpEnuE5JXxm+jO1u8GS/TIAECAhIgYMRuiFEZ7iUgDyixHrjnz9/7NYHJFdYdtxmxAQICEiAgIAECAhIGZy0yJiABAgKyIY5aw72c5tMYIclVRur9NEiAgIBslJvgUoJtaJ2APCHTRiUo2Wu+rdhutlmDbEipDdqnI8I+GiRAQINsmPYHdQnIk97TMwF15e+05jSWtaUU28I+ArJT8x1A24TjrEECBAQkQEBAXuAcRLI4si3aZvcTkAABAdkpB2XgOkexG3P2KhhjFRwnIBtWIvSeOp+Te3mDPMeIDRDQIAso1cJe0/YIrQlwhe3nGAGZyHzj/Q5eGzZrLJPUISCTE4yUYls6zhokQEBAFtLCVTWvySg2iqXlGo4TkAABAQkQEJCFtTjKtPg7s2xpqcfre56AHJB1SNjHaT4DWWsS7kDenvlFBZpieRokQECDrKCFG0D4EKe+LL1+XtPrBORA1kI7e6DDE4zYlbRw4jj9MBHUISABAkbsgXxaxdZt1Izb7dEY6xCQA9o6paeFg0wsE5RlGbEBAgKyshbe0aNTRBxoYnQCkk2Csg1eo/KsQd6glzW9aAfs4bG1QADeT4MECGiQN1k7xaZ1S82m5uMc7ZSkPc1Ru6xDQFKFuwPRAwHJou9AK9FOSrbM0cJ27bXQHOuyBgkQ0CBv1soR7e810yO/75FG0/O6LH0QkKw6ekBk63uMhNui59x4fT8jNreaB6j2SGYa5AMyj5Z3fLZJxsfdGu3xHhokP9jxnvO5pPN73dfr8SwN8kEtHLDJ/vv1YGtt8b3yNerSIAECAvJh2RtB9t+vdxr8s4zYCWQ+aDNN7uJTw943HuP1szRIgICABAgYsTnEWH3d0VHZaP0cDTKR7DuCcLxOOLZFQLKLcGREAjKZrI3hjt/LJymSjTVIdst+OlJmZ0LfG8XzBGRC2T9z5UhQ7tnJX7N/tu5qsAnGPIzYAAEBSTWa0HGes1yM2MllXvdbuhvRkR387GPKvgRBPwQkl5xtPCXCsTc9P7ZWGbEBAhpkI1q4ue4eZx5D782q98fXMgHZkB5CstQpQhmfB+c69seIDRDQIBuT+aj2EVttOHOzmv9ulg36JSAb1dO4feVnaz8HZ+78XfJ7eZaApGtnz5msFXjCsS3WIAECGmTDehizr1paD1xraWuNsma70xzbJCAb18tBm1L2huPW95YkHNtlxO6EnTAnr0vbBCRAwIjdEeN2HppjHzTIDtk5n+X574eABAgIyE5pMffziYz9EZAds8Pex/PcJwdpBuDgTR1CsX8aJEBAgxyIJlmG5jgOATkgnwp4jmAcjxF7cHb6fTxPYxKQAAEjNm6bFtAaEZBM02Rd8kMo8s2IDRDQIPllxDapObJEQLLqaHC0FKhCkS0CkqJKhk4UtoKNu1iDBAgISNJauhuR9sidjNg0QTDyBA2S9IQjTxGQAAEBCRAQkAABAQkQEJAAAQEJEBCQAIHdJ4q/385GA8aiQQIEBCRAQEACBAQkQEBAAgQEJEBAQAIEBCRAQEACBP4PRuyXjkO3gIMAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 400x400 with 1024 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "batch_size = 16\n",
    "patch_size = 7  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "x = train_gen.next()\n",
    "image = x[0][0]\n",
    "\n",
    "\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size = (image_size, image_size)\n",
    ")\n",
    "\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f'Image size: {image_size} X {image_size}')\n",
    "print(f'Patch size: {patch_size} X {patch_size}')\n",
    "print(f'Patches per image: {patches.shape[1]}')\n",
    "print(f'Elements per patch: {patches.shape[-1]}')\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype('uint8'))\n",
    "    plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:45:56.047457400Z",
     "start_time": "2024-03-18T20:45:35.355381400Z"
    }
   },
   "id": "a62c75c409965d67",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from vit_keras import vit\n",
    "\n",
    "vit_model = vit.vit_b16(\n",
    "        image_size = image_size,\n",
    "        activation = 'softmax',\n",
    "        pretrained = True,\n",
    "        include_top = False,\n",
    "        pretrained_top = False,\n",
    "        classes = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:46:41.086987600Z",
     "start_time": "2024-03-18T20:46:37.135998700Z"
    }
   },
   "id": "e1778486eff1006b",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vision_transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vit-b16 (Functional)        (None, 768)               85798656  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 768)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 768)              3072      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               98432     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,911,107\n",
      "Trainable params: 85,909,315\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        vit_model,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(128, activation = tfa.activations.gelu),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(64, activation = tfa.activations.gelu),\n",
    "        tf.keras.layers.Dense(32, activation = tfa.activations.gelu),\n",
    "        tf.keras.layers.Dense(3, 'softmax')\n",
    "    ],\n",
    "    name = 'vision_transformer')\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:46:44.210181900Z",
     "start_time": "2024-03-18T20:46:41.082419900Z"
    }
   },
   "id": "8ff0fc10eb56bd7e",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b8b890de048e001f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
